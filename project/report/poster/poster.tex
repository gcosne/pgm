%==============================================================================
%== template for LATEX poster =================================================
%==============================================================================
%
%--A0 beamer slide-------------------------------------------------------------
\documentclass[final]{beamer}
\usepackage[orientation=portrait,size=a0,
            scale=1.25         % font scale factor
           ]{beamerposter}
           
\geometry{
  hmargin=2.5cm, % little modification of margins
}


% MY PACKAGES
\usepackage[export]{adjustbox}


%
\usepackage[utf8]{inputenc}

\linespread{1.15}
%
%==The poster style============================================================
\usetheme{sharelatex}

%==Title, date and authors of the poster=======================================
\title
[Probabilistic Graphical Models Poster Session, Wed 4 Jan 2017] % Conference
{ % Poster title
Alignment models for statistical translation
}

\author{ % Authors
Thomas Debarre, Matthieu Kirchmeyer, Sylvain Truong, Nicolas Zhang
}
%\institute{}
\institute
%[Very Large University] % General University
{\mbox{}
%\inst{1} Very Large University, Neverland\\[0.3ex]
%\inst{2} Other University, Neverland\\[0.3ex]
%\inst{3} Yet Another University, Neverland
}
\date{\today}



\begin{document}
\begin{frame}[t]
%==============================================================================
\begin{multicols}{3}
%==============================================================================
%==The poster content==========================================================
%==============================================================================

\section{Introduction}

This project explores three methods to solve the problem of word alignments for a bilingual corpus : conventional mixtures models (IBM1, IBM2) and a first-order HMM model developped in \cite{ref1}. 

The goal is to translate a text given in a language (French in all that follows) to another language (English) taking into account one-to-many alignments or null words; the quality of the translation relies on the quality of the word alignments.
% I would not say "translate" but rather understand the underlying linguistics between two languages. In our study, doing so boils down to finding most probable alignments.  


We evaluated our algorithms on a small bilingual French-English dataset $\mathcal{D} = \{ (\mathbf{f}^{(1)},\mathbf{e}^{(1)}), \dots , (\mathbf{f}^{(N)},\mathbf{e}^{(N)})\}$ which consists of $N = 22$ French sentences composed of 4 to 10 words with their translated English equivalents. 

\section{Statistical translation models}


\structure{Your text with scientific results or something...} 

\begin{equation}
H = \sum_{i=1}^{N} h_{D}(i) + \sum_{j>i=1}^{N} C_{ij}
\end{equation}


In Ref.~\cite{ref1}...
In Refs.~\cite{ref1,ref2}...
On webpage~\cite{web}...

\subsection{IBM models}

\subsubsection{IBM1}


\subsubsection{IBM2}

\vskip1ex
\begin{table}
\centering
\caption{This is a table with scientific results.}
\begin{tabular}{ccccc}
\hline\hline
1 & 2 & 3 & 4 & 5\\
\hline
aaa & bbb & ccc & ddd & eee\\
aaaa & bbbb & cccc & dddd & eeee\\
aaaaa & bbbbb & ccccc & ddddd & eeeee\\
aaaaaa & bbbbbb & cccccc & dddddd & eeeeee\\
1.000 & 2.000 & 3.000 & 4.000 & 5.000\\
\hline\hline
\end{tabular}
\end{table}
\vskip2ex

Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 


\subsection{HMM-based alignment models}

The HMM-based alignment models were introduced by \textit{Vogel and al.} and aim at modeling the joint probability of a French sentence $\textbf{f}$, of length $J$ and an alignment $\textbf{a}\in \{1,\dots,I\}^J$, given a English sentence $\textbf{e}$ of length $I$.
Without, loss of generality, this probability can be expressed as (chain-rule and independance of $\textbf{f}$ and $\textbf{a}$):
\begin{align*}
Pr(\textbf{f},\textbf{a}|\textbf{e}) &= Pr(f_0,a_0|\textbf{e}) \prod_{j=1}^J Pr(f_j,a_j|f_{1}^{j-1},a_{1}^{j-1},\textbf{e})\\
&= Pr(f_0|\textbf{e}) \cdot Pr(a_0|\textbf{e})\\
&\cdot \prod_{j=1}^J Pr(f_j|f_{1}^{j-1},a_{1}^{j-1},\textbf{e}) Pr(a_j|f_{1}^{j-1},a_{1}^{j-1},\textbf{e})
\end{align*}

The HMM model reduced the generality of the previous formula by assuming first-order dependance of alignments and translation probability of French word at position $j$ to be only dependent on the English word at position $a_j$, thus yielding the HMM model:

\begin{align*}
Pr(\textbf{f},\textbf{a}|\textbf{e}) &= p(f_0|e_{a_0}) p(a_0)\\
&\cdot \prod_{j=1}^J p(f_j|e_{a_{j}}) \cdot p(a_j|a_{j-1},I)
\end{align*}

\vskip1ex
\begin{figure}
\centering
%\includegraphics[width=0.99\columnwidth]{logo.png}
\adjincludegraphics[width=0.99\columnwidth,trim={{0.03\width} {0.6\height} {0.02\width} 0},clip]{figures/hmm.pdf}
\caption{The HMM-based alignment model}
\label{fig:hmm}
\end{figure}
\vskip2ex

Figure~\ref{fig:hmm} presents the graphical model associated with HMM-based alignement models. What can be noticed is that, in this context, each sentence pair represents a Hidden Markov Model which parameters are shared with all other sentences of the corpus.
The \textbf{parameters for the HMM model} are
\begin{align*}
\Theta &= \lbrace\\
& p(i) &\mbox{   the initial alignment probabilities ($p(a_0)$)}\\ 
& p(i|i',I) &\mbox{   the transition matrix}\\
& p(f|e) &\mbox{   the emission (translation) probabilities}\rbrace
\end{align*}

A further assumption from \textit{Vogel and al.} is that alignment transition probabilities \textbf{only depend on relative positions}: $p(i|i',I) = p(i'-i|I)$

Just as for the IBM models, the observations are the sequences of French words in French sentences, while the alignments (and thus the corresponding English words) act as hidden variables. A way to solve this problem is to use an \textbf{EM principle}.
The \textbf{Expectation step} consists in computing alignment unary and binary probabilities in each sentence pair $(\textbf{f},\textbf{e})$. 

\begin{align*}
\gamma_i(j) &= p(a_j=i|\textbf{f})\\
\xi_{k,l}(j) &= p(a_j=k,a_{j+1}=l|\textbf{f})
\end{align*}

This can be performed using the Forward-Backward algorithm.
The \textbf{Maximisation step} consists in re-estimating the model's parameters according to the previously computed probabilities.

The \textbf{Viterbi} algorithm is then used to retrieve the most likely alignements in the corpus, according to the computed transition and emission probabilities.

\section{Results and discussions}

\subsection{The experimental setup}

Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something...

\subsubsection{Test data}
 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 

\subsubsection{Evaluation method}
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 



\subsubsection{Example results}
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 
Your text with scientific results or something... 

\section{Summary and conclusions}




%==============================================================================
%==End of content==============================================================
%==============================================================================

%--References------------------------------------------------------------------

\subsection{References}

\begin{thebibliography}{99}

\bibitem{ref1} S. Vogel, H. Ney, and C. Tillmann, HMM-based word alignment in statistical translation

\bibitem{ref2} J.~Doe, J. Smith, Other article name, \textit{Phys. Rev. Lett.}

\bibitem{web} \url{http://www.google.pl}

\end{thebibliography}
%--End of references-----------------------------------------------------------

\end{multicols}

%==============================================================================
\end{frame}
\end{document}
